\chapter{Experiments}


\section{Benchmark}

We perform benchmarks on five bivariate cause-effect datasets\footnote{ The TCEP dataset 
can be found \href{https://webdav.tuebingen.mpg.de/cause-effect/}{\color{blue}{here}} and 
all the other datasets can be found 
\href{https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/3757KX}{\color{blue}{here}}
}, covering a wide range of associations:

% \begin{enumerate}[itemsep=-1.8em, topsep=0pt]
\begin{enumerate}[noitemsep, topsep=0pt]

    \item \textbf{Cha} (300 cause-effect pairs) pairs from the challenge of \cite{chalearn}
    \item \textbf{Net} (300 cause-effect pairs) artificial cause-effect pairs generated using 
            random distributions as causes, and neural networks as causal mechanisms
    \item \textbf{Gauss} (300 cause-effect pairs) generated by \cite{Mooij2016jmlr}, using random 
      mixtures of Gaussians as causes, and Gaussian process priors as causal mechanisms.
    \item \textbf{Multi} (300 cause-effect pairs) built with random linear and 
    polynomial causal mechanisms (by \cite{goudet2017causal}). In this dataset, 
    additive or multiplicative noise, is applied before or after the causal mechanism.
    \item \textbf{TCEP} (108 cause-effect pairs)\footnote{Note that 6 of these pairs are not bivariate; the 
    dataset is also weighted as some samples come from similar data generation processes. } 
     is the TÃ¼bingen Cause Effect Pair data set which consists of various 
    domains such as climatology, finance, and medicine (\cite{Mooij2016jmlr}).

\end{enumerate}

We use the results reported by \cite{goudet2017causal}. We compare against the following algorithms
in the benchmark: ANM (\cite{Mooij2016jmlr}) with Gaussian Process regression and HSIC score as described 
in the introduction. IGCI \cite{daniusis2012inferring} with entropy estimator and Gaussian reference measure.
A  pairwise version of LiNGAM \cite{shimizu2011directlingam}.  Jarfo (Fonollosa, 2016), using a random forest 
causal classifier trained from the ChaLearn Cause-effect pairs on top of 150 features including ANM, IGCI,
CDS, LiNGAM, regressions, HSIC tests (\cite{fonollosa2019conditional}). GCNN without the approximated MMD (\cite{goudet2017causal})

Following the performance metric used by \cite{goudet2017causal}, we report the AUPR (Area Under the Precision/Recall curve)
values for each data set. For the TCEP we also report the weighted accuracy along with the AUPR score. 

For each  competitor method, a leave-one-dataset-out scheme 
is used to select the best hyperparameters for each method (as reported by \cite{goudet2017causal}). For 
our method we do no such thing; on our own synthetic data we performed some simple grid search to find 
hyperparameters that performed well in practice. 

We report the scores in table \ref{tab:AUPR}. The first good news is that we are never worse than any other 
method! In terms of accuracy with TCEP we perform reasonably well, and somewhat surprisingly, in the  
AUPC metric we outperform CGNN. 

We found the best results by using TwinTest with polynomial regression and as a score function:

$$
    C(P_k) = \operatorname{max}_{i, j} d(p_i, p_j)
$$

with $d$ as the $l_1$ metric. 




\begin{table}[H]
    \centering


    \begin{tabular}{lccccc}
        \hline method & Cha & Net & Gauss & Multi & TCEP \\
        % \hline Best fit & 56.4 & 77.6 & 36.3 & 55.4 & 58.4 (44.9) \\
        LiNGAM & 54.3 & 43.7 & 66.5 & 59.3 & 39.7 (44.3) \\
        % CDS & 55.4 & 89.5 & 84.3 & 37.2 & 59.8 (65.5) \\
        IGCI & 54.4 & 54.7 & 33.2 & 80.7 & 60.7 (62.6) \\
        ANM & 66.3 & 85.1 & 88.9 & 35.5 & 53.7 (59.5) \\
        % PNL & 73.1 & 75.5 & 83.0 & 49.0 & 68.1 (66.2) \\
        Jarfo & 79.5 & 92.7 & 85.3 & 94.6 & 54.5 (59.5) \\
        % GPI & 67.4 & 88.4 & 89.1 & 65.8 & 66.4 (62.6) \\
        CGNN  & 73.6 & 89.6 & 82.9 & 96.6 & 79.8 (74.4) \\
        \hline TwinTest & 66.3 & 81.9 & 85.1 & 39.8 & 82.0 (62.4) \\
        \hline
    \end{tabular}

    \caption{Cause-effect relations: Area Under the Precision Recall curve
     on 5 benchmarks for the cause-effect experiments (weighted accuracy 
     in parenthesis for TCEP).}   
    \label{tab:AUPR}
\end{table}


% \begin{table}[H]
%     \centering

%     \begin{tabular}{lcc}
%         \hline Model & TCEP & TCEP with 75 samples \\
%         \hline BCI & 0.64 & 0.60 \\
%         ANM-HSIC & 0.63 & 0.54 \\
%         ANM-MML & 0.58 & 0.56 \\
%         IGCI & 0.66 & 0.62 \\
%         CGNN & 0.70 & 0.69 \\
%         \hline TwinTest & 0.62 & TODO \\
%         \hline
%     \end{tabular}
%     \caption{Accuracy for TCEP Benchmark} 
%     \label{tab:acc}
% \end{table}

% Table \ref{tab:acc} is taken from \cite{kurthen2018bayesian}
