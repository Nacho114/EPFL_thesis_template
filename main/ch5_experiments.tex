\chapter{Experiments}


\section{Benchmark}

We perform benchmarks on five bivariate cause-effect datasets\footnote{ The TCEP dataset 
can be found \href{https://webdav.tuebingen.mpg.de/cause-effect/}{\color{blue}{here}} and 
all the other datasets can be found 
\href{https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/3757KX}{\color{blue}{here}}
}, covering a wide range of associations:

% \begin{enumerate}[itemsep=-1.8em, topsep=0pt]
\begin{enumerate}[noitemsep, topsep=0pt]

    \item \textbf{Cha} (300 cause-effect pairs) pairs from the challenge of \cite{chalearn}.
    \item \textbf{Net} (300 cause-effect pairs) artificial cause-effect pairs generated using 
            random distributions as causes, and neural networks as causal mechanisms.
    \item \textbf{Gauss} (300 cause-effect pairs) generated by \cite{Mooij2016jmlr}, using random 
      mixtures of Gaussians as causes, and Gaussian process priors as causal mechanisms.
    \item \textbf{Multi} (300 cause-effect pairs) built with random linear and 
    polynomial causal mechanisms (by \cite{goudet2017causal}). In this dataset, 
    additive or multiplicative noise, is applied before or after the causal mechanism.
    \item \textbf{TCEP} (108 cause-effect pairs)\footnote{Note that 6 of these pairs are not bivariate; the 
    dataset is also weighted as some samples come from similar data generation processes. } 
     is the TÃ¼bingen Cause Effect Pair data set which consists of various 
    domains such as climatology, finance, and medicine (\cite{Mooij2016jmlr}).

\end{enumerate}

We use the results reported by \cite{goudet2017causal}. We compare against the following algorithms
in the benchmark: ANM (\cite{Mooij2016jmlr}) with Gaussian Process regression and HSIC score as described 
in the introduction. IGCI \cite{daniusis2012inferring} with entropy estimator and Gaussian reference measure.
A  pairwise version of LiNGAM \cite{shimizu2011directlingam}.  Jarfo (Fonollosa, 2016), using a random forest 
causal classifier trained from the ChaLearn Cause-effect pairs on top of 150 features including ANM, IGCI,
CDS, LiNGAM, regressions, HSIC tests (\cite{fonollosa2019conditional}). GCNN without the approximated MMD (\cite{goudet2017causal})



In the first setting we want to see how well we perform in terms of accuracy with real date, i.e.
TCEP. For each  competitor method, a leave-one-dataset-out scheme 
is used to select the best hyperparameters for each method (as reported by \cite{goudet2017causal}). 
We report the scores in table \ref{tab:acc}; as we can see see, twin test is competitive with 
other methods.


\vspace{0.03\textheight}
\begin{table}[H]
    \centering
    \begin{tabular}{lccccc}
        \hline method  & TCEP \\
        LiNGAM &   44.3 \\
        IGCI  &  62.6 \\
        ANM  &  59.5 \\
        Jarfo  &  59.5 \\
        CGNN   &  74.4 \\
        \hline TT & 62.4 \\
        \hline
    \end{tabular}

    \caption{ weighted accuracy 
     in parenthesis for TCEP.}   
    \label{tab:acc}
\end{table}


The standard TwinTest (TT) algorithm that we use has the following setup:

The score is the maximum pairwise distance:

$$
    C(P_k) = \operatorname{max}_{i, j} d(p_i, p_j)
$$

with $d(x, y) = \norm{x - y}_1$.

We use polynomial regression via model selection as described in section 4.1 For the cluster size
we use a greedy approach: given some $\rho > 0$, $m \in \N$, and data $\mathcal{D}$, 
we start by finding $m$ clusters
using k-means, say $\mathcal{D}_1, ..., \mathcal{D}_m$, if 
$\min_i |\mathcal{D}_i| \geq \rho n$, where $n = |\mathcal{D}|$, then we are done; 
otherwise we try again with $m - 1$ clusters, and we keep going until it halts because of the 
condition being met or when $m = 2$. 

In practice we set $m = 8$, and we let $\rho$ vary\footnote{More details about the implementation can be found 
\href{https://github.com/Nacho114/bivariate-causal-inference}{\color{blue}{here}}.} 
with sample size, intuitively if we have many samples, then we can support a lower $\rho$.
For the bin size we choose roughly $\log(k)$ where $k$ is the size of a cluster.

We also try the following variants of TT:

\begin{itemize}
    \item[--] TT\textsubscript{mmd}: Standard TT with 
        $d(x, y) = \operatorname{MMD}(x, y)$, using a Gaussian kernel and the median heuristic\footnote{
            As a reminder, the median heuristic is: 
            $\hat{\gamma}(\mathbf{u}):=\operatorname{median}\left\{\left\|u_{i}-u_{j}\right\|:  i<j ,\left\|u_{i}-u_{j}\right\| \neq 0\right\}$}
         to determinre the bandwidth.
    \item[--] TT\textsubscript{2-partitions}: Standard TT with fixed partition size set to $2$.
    \item[--] TT\textsubscript{Neural net}: Standard TT using neural network as regression.
    \item[--] TT\textsubscript{$\mu$-score}: Standard TT with $d(x, y) = \norm{x - y}_1$ and score:
    $$
    C(P_k) = \frac{1}{\binom{k}{2}} \sum_{i < j} d(p_i, p_\mu)
    , \quad p_\mu = \frac{1}{k} \sum_i p_i
    $$
\end{itemize}


In order to see how the variants compare we run them on all the benchmarks and report the 
scores in table \ref{tab:own_perf}. We also include ANM and IGCI but do not do any fine 
tuning and use them right out of the box --- we do so since we do not fine tune any 
of the variants of TT as well as TT. 

We remark that overall, TwinTest in its standard form has the best performance on TCEP, 
and is close to the top in most of the benchmarks. It seems 
that using partition numbers adaptively is better than when fixing it with 2, as is 
done in TT\textsubscript{2-partitions}. Surprisingly, the MMD does not seem to 
offer much advantage compared to the $l_1$ distance.
When using neural networks with TT\textsubscript{Neural net}, performance
is also lost; this could probably be improved by using a better model selection process 
for the neural network. Using a different score as in TT\textsubscript{$\mu$-score} 
does not seem to make a big difference. 

\vspace{0.03\textheight}
\begin{table}[H]
    \centering
    \begin{tabular}{lccccc}
        \hline method & Cha & Net & Gauss & Multi & TCEP \\
        ANM & 67.3 & 76.3 & 80.0 & 35.3 & 52.5\\
        IGCI & 55.0 & 57.0 & 21.3 & 68.0 & 60.3\\
        % A1 & 65.0 & 75.3 & 78.7 & 36.3 & 57.2\\
        TT\textsubscript{mmd} & 65.7 & 75.7 & 77.0 & 36.3 & 57.3\\
        TT\textsubscript{2-partitions} & 67.0 & 72.0 & 73.0 & 43.7 & 60.6\\
        TT\textsubscript{Neural net} & 62.0 & 68.0 & 76.7 & 39.7 & 59.7\\
        TT\textsubscript{$\mu$-score}  & 67.3 & 70.7 & 76.0 & 48.0 & 62.3\\
        TT & 67.3 & 68.3 & 76.7 & 42.3 & 62.4\\
        \hline
    \end{tabular}

    \caption{Cause-effect relations: Accuracy
     on 5 benchmarks for the cause-effect experiments (weighted accuracy 
     for TCEP).}   
    \label{tab:own_perf}
\end{table}


% \begin{table}[H]
%     \centering

%     \begin{tabular}{lcc}
%         \hline Model & TCEP & TCEP with 75 samples \\
%         \hline BCI & 0.64 & 0.60 \\
%         ANM-HSIC & 0.63 & 0.54 \\
%         ANM-MML & 0.58 & 0.56 \\
%         IGCI & 0.66 & 0.62 \\
%         CGNN & 0.70 & 0.69 \\
%         \hline TwinTest & 0.62 & TODO \\
%         \hline
%     \end{tabular}
%     \caption{Accuracy for TCEP Benchmark} 
%     \label{tab:acc}
% \end{table}

% Table \ref{tab:acc} is taken from \cite{kurthen2018bayesian}
% \begin{table}[H]
%     \centering
%     \begin{tabular}{lccccc}
%         \hline method & Cha & Net & Gauss & Multi & TCEP \\
%         % \hline Best fit & 56.4 & 77.6 & 36.3 & 55.4 & 58.4 (44.9) \\
%         LiNGAM & 54.3 & 43.7 & 66.5 & 59.3 & 39.7 (44.3) \\
%         % CDS & 55.4 & 89.5 & 84.3 & 37.2 & 59.8 (65.5) \\
%         IGCI & 54.4 & 54.7 & 33.2 & 80.7 & 60.7 (62.6) \\
%         ANM & 66.3 & 85.1 & 88.9 & 35.5 & 53.7 (59.5) \\
%         % PNL & 73.1 & 75.5 & 83.0 & 49.0 & 68.1 (66.2) \\
%         Jarfo & 79.5 & 92.7 & 85.3 & 94.6 & 54.5 (59.5) \\
%         % GPI & 67.4 & 88.4 & 89.1 & 65.8 & 66.4 (62.6) \\
%         CGNN  & 73.6 & 89.6 & 82.9 & 96.6 & 79.8 (74.4) \\
%         \hline TwinTest & 66.3 & 81.9 & 85.1 & 39.8 & 82.0 (62.4) \\
%         \hline
%     \end{tabular}

%     \caption{Cause-effect relations: Area Under the Precision Recall curve
%      on 5 benchmarks for the cause-effect experiments (weighted accuracy 
%      in parenthesis for TCEP).}   
%     \label{tab:perf}
% \end{table}



