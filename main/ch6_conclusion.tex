\chapter{Conclusion}

We have introduced a new method to perform causal inference in the bivariate additive 
noise model. The method is simple, and is different from ANM methods in that it 
exploits the residual directly rather than testing for independence between 
the residual and input. This has the advantage of avoiding independence testing 
which is known to be hard. The drawback is that we assume that the noise is independent 
between each sample. The method is also theoretically sound as we were able to prove that 
it is consistent asymptotically. While it is not as good as state of the art, it is
competitive: this shows that exploiting noise alone is also a viable 
line of attack to infer the causal direction in the ANM setting. 


% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO
% TODODODODODODODODO

% \subsection{TODO stuff}

% TODO (will remove this later, just as a reminder)
% + unsupervised 
% + fast 
% + no independence test needed
% + theoretically sound

% - iid on Z assumption
% - acc

% TODO:

% IGCI, at least mention a bit

% Some observations:

% While it could be $F(X, Z)$, often it might be $F(X, Z) + Z_2$ since there is often measurement error
% so noise additivity is a good assumption. 

% Standardize residual notation! $e_x$...

% Briefly discuss AIC / model selection
% intution about using poly reg since it's local
% aprox
% https://stats.stackexchange.com/questions/9171/
% aic-or-p-value-which-one-to-choose-for-model-selection

